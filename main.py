import streamlit as st
import pandas as pd
import pyreadstat
import os
import re
from tkinter import Tk, filedialog

st.set_page_config(page_title="üìë Tabular Viewer", layout="wide")
def select_directory():
    root = Tk()
    root.withdraw()  # –°–∫—Ä—ã—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–µ –æ–∫–Ω–æ
    root.attributes('-topmost', True)  # –û–∫–Ω–æ –ø–æ–≤–µ—Ä—Ö –¥—Ä—É–≥–∏—Ö
    folder_path = filedialog.askdirectory(title="–í–∏–±–µ—Ä—ñ—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –∑ –¥–∞–Ω–∏–º–∏")
    root.destroy()
    return folder_path

DEFAULT_DIR = "data"
st.sidebar.header("üîß –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
custom_dir = st.sidebar.text_input("–®–ª—è—Ö –¥–æ –∫–∞—Ç–∞–ª–æ–≥—É –∑ –¥–∞–Ω–∏–º–∏:", value=DEFAULT_DIR)
DATA_DIR = custom_dir.strip()
if st.sidebar.button("üìÅ –í–∏–±–µ—Ä—ñ—Ç—å –∫–∞—Ç–∞–ª–æ–≥"):
    selected_dir = select_directory()
    if selected_dir:
        DATA_DIR = selected_dir
        st.sidebar.success(f"–í–∏–±—Ä–∞–Ω–æ –∫–∞—Ç–∞–ª–æ–≥: {DATA_DIR}")
    else:
        DATA_DIR = "data"
else:
    DATA_DIR = "data"  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

st.title("üìë Tabular Viewer")

if not os.path.exists(DATA_DIR):
    st.error(f"–ü–∞–ø–∫–∞ '{DATA_DIR}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –°—Ç–≤–æ—Ä–∏ –ø–∞–ø–∫—É —ñ –¥–æ–¥–∞–π —Ñ–∞–π–ª–∏ —Ç—É–¥–∏.")
    st.stop()

files = [f for f in os.listdir(DATA_DIR) if not f.startswith('.') and os.path.isfile(os.path.join(DATA_DIR, f))]

if not files:
    st.warning(f"–ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É —É –ø–∞–ø—Ü—ñ {DATA_DIR}/")
    st.stop()

selected = st.sidebar.selectbox("–û–±–µ—Ä—ñ—Ç—å —Ç–∞–±–ª–∏—Ü—é –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É:", sorted(files))


@st.cache_data
def load_data_with_meta(file):
    ext = os.path.splitext(file)[1].lower()
    path = os.path.join(DATA_DIR, file)
    try:
        if ext == ".sas7bdat":
            df, meta = pyreadstat.read_sas7bdat(path)
            return df, meta
        elif ext == ".xpt":
            df, meta = pyreadstat.read_xport(path)
            return df, meta
        elif ext == ".csv":
            return pd.read_csv(path), None
        elif ext == ".xlsx":
            return pd.read_excel(path), None
        else:
            return None, None
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É {file}: {e}")
        return None, None
@st.cache_data
def parse_sdtm_metadata(path):
    try:
        with open(path, encoding='utf-8') as f:
            lines = f.readlines()
        parsed = []
        for line in lines:
            parts = line.strip().split("$")
            if len(parts) >= 5:
                parsed.append({
                    "Dataset": parts[2],
                    "Variable": parts[3],
                    "Label": parts[4],
                    "Type": parts[5] if len(parts) > 5 else ""
                })
        return pd.DataFrame(parsed)
    except Exception as e:
        return None
    
@st.cache_data
def load_all_metadata():
    metadata_files = [f for f in os.listdir(DATA_DIR) if f.endswith(('.csv', '.xlsx')) and not f.startswith('.')]
    specs = {}
    for file in metadata_files:
        path = os.path.join(DATA_DIR, file)
        try:
            if file == "SDTM_spec_Variables.csv":
                df = parse_sdtm_metadata(path)
            elif file.endswith(".csv"):
                df = pd.read_csv(path)
            elif file.endswith(".xlsx"):
                df = pd.read_excel(path)
            else:
                continue
            if df is not None and any(col.lower() in df.columns.str.lower().tolist() for col in ["variable", "label"]):
                specs[file] = df
        except: continue
    return specs

@st.cache_data
def find_matching_metadata(data_filename, df, specs):
    base_name = os.path.splitext(data_filename)[0].lower()
    candidates = []
    for spec_name, spec_df in specs.items():
        cols = spec_df.columns.str.lower()
        if any("variable" in col for col in cols):
            candidates.append((spec_name, spec_df))

    for name, df_spec in candidates:
        if re.search(base_name, name.lower()):
            return df_spec

    for name, df_spec in candidates:
        cols = df_spec.columns.str.lower()
        if "dataset" in cols:
            if df_spec["Dataset"].astype(str).str.lower().str.contains(base_name).any():
                return df_spec[df_spec["Dataset"].str.lower() == base_name]

    for name, df_spec in candidates:
        if "Variable" in df_spec.columns:
            common = set(df_spec["Variable"]).intersection(df.columns)
            if len(common) / len(df.columns) > 0.3:
                return df_spec

    return None

@st.cache_data
def describe_column(col, metadata_df, _meta):
    # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Ç–∞–±–ª–∏—Ü—ã —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if metadata_df is not None and "Variable" in metadata_df.columns:
        row = metadata_df[metadata_df["Variable"] == col]
        if not row.empty:
            return row.iloc[0].to_dict()

    # –ï—Å–ª–∏ –µ—Å—Ç—å pyreadstat.meta ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç—Ç—É–¥–∞
    desc = {}
    if _meta:
        if hasattr(_meta, "column_names_to_labels"):
            desc["Label"] = _meta.column_names_to_labels.get(col, "")
        if hasattr(_meta, "readstat_variable_types"):
            desc["Type"] = _meta.readstat_variable_types.get(col, "")
        if hasattr(_meta, "variable_storage_width"):
            desc["Length"] = _meta.variable_storage_width.get(col, "")
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ–∑–º–æ–∂–Ω–æ–µ –ø–æ–ª–µ format –≤ –±—É–¥—É—â–µ–º (–µ–≥–æ –ø–æ–∫–∞ –Ω–µ—Ç –≤ pyreadstat)
        if hasattr(_meta, "formats"):
            desc["Format"] = _meta.formats.get(col, "")
    return desc if desc else None



df, meta = load_data_with_meta(selected)
all_specs = load_all_metadata()
matched_metadata = find_matching_metadata(selected, df, all_specs) if df is not None else None




tab1, tab2 = st.tabs(["üìã –ú–µ—Ç–∞–¥–∞–Ωi","üìÑ –î–∞–Ωi"])

with tab2:
    st.dataframe(df, use_container_width=True)
    st.markdown(f"**–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä—è–¥–∫—ñ–≤:** {len(df)} | **–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫:** {len(df.columns)}")

with tab1:
    if meta:
        meta_rows = []
        for idx, col in enumerate(meta.column_names):
            desc = describe_column(col, matched_metadata, _meta=meta) or {}
            meta_rows.append({
                "‚Ññ": idx + 1,
                "Variable": col,
                "Label": desc.get("Label", ""),
                "Type": desc.get("Type", ""),
                "Length": desc.get("Length", ""),
                "Format": desc.get("Format", "")
            })
        meta_df = pd.DataFrame(meta_rows)
        st.dataframe(meta_df, use_container_width=True)
    else:
        st.info("–ú–µ—Ç–∞–¥–∞–Ω—ñ SAS –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ.")